{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "# from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes: list[str] = []\n",
    "\n",
    "with open('land_use_images\\\\label_map.json', 'rb') as f:\n",
    "    classes = json.loads(f.read())\n",
    "\n",
    "classes = [x for x in classes.keys()]\n",
    "(image_width, image_height) = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_generator: image.ImageDataGenerator = image.ImageDataGenerator(\\n    rotation_range=40,\\n    width_shift_range=0.2,\\n    height_shift_range=0.2,\\n    rescale=1./255,\\n    shear_range=0.2,\\n    zoom_range=0.2,\\n    horizontal_flip=True,\\n    fill_mode='nearest'\\n)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_generator: image.ImageDataGenerator = image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing_data(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7350 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "train_dataset = train_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "test_dataset = train_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\validation\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "validation_dataset = train_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (image_width, image_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.add(Conv2D(32, (2, 2), input_shape=input_shape))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Conv2D(32, (2, 2)))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Conv2D(64, (2, 2)))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Flatten())\\nmodel.add(Dense(64))\\nmodel.add(Activation('relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(1))\\nmodel.add(Activation('sigmoid'))\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(InputLayer(shape=input_shape))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=21, activation='softmax'))  # Supondo 10 classes para a saída\n",
    "\n",
    "#model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(258, 3, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(258, 3, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(rate=0.5))\n",
    "#model.add(Dense(64, activation=\"relu\")),\n",
    "#model.add(Dropout(rate=0.5))\n",
    "#model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m147/250\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 1s/step - accuracy: 0.0681 - loss: 5.8134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 965ms/step - accuracy: 0.0739 - loss: 4.9104 - val_accuracy: 0.0476 - val_loss: 3.8917\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 991ms/step - accuracy: 0.1784 - loss: 2.6931 - val_accuracy: 0.0476 - val_loss: 4.5760\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 948ms/step - accuracy: 0.3848 - loss: 2.0693 - val_accuracy: 0.0476 - val_loss: 5.6213\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 987ms/step - accuracy: 0.6111 - loss: 1.3119 - val_accuracy: 0.0476 - val_loss: 6.7419\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.7972 - loss: 0.7332 - val_accuracy: 0.0476 - val_loss: 7.1665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x246e9722dd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, steps_per_epoch=250, batch_size=32, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 401ms/step - accuracy: 0.0515 - loss: 7.2375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.166549205780029, 0.0476190485060215]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
