{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "# from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes: list[str] = []\n",
    "\n",
    "with open('land_use_images\\\\label_map.json', 'rb') as f:\n",
    "    classes = json.loads(f.read())\n",
    "\n",
    "classes = [x for x in classes.keys()]\n",
    "(image_width, image_height) = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing_data(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7350 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "train_dataset = train_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "test_dataset = test_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset: tf.data.Dataset = image_dataset_from_directory(\n",
    "    \"land_use_images\\\\images_train_test_val\\\\validation\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50,\n",
    "    image_size=(image_width, image_height),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "validation_dataset = validation_dataset.map(normalizing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (image_width, image_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.add(Conv2D(32, (2, 2), input_shape=input_shape))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Conv2D(32, (2, 2)))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Conv2D(64, (2, 2)))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n \\nmodel.add(Flatten())\\nmodel.add(Dense(64))\\nmodel.add(Activation('relu'))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(1))\\nmodel.add(Activation('sigmoid'))\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(InputLayer(shape=input_shape))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=21, activation='softmax'))  # Supondo 10 classes para a saída\n",
    "\n",
    "#model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(258, 3, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(258, 3, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(rate=0.5))\n",
    "#model.add(Dense(64, activation=\"relu\")),\n",
    "#model.add(Dropout(rate=0.5))\n",
    "#model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m147/250\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 2s/step - accuracy: 0.0633 - loss: 3.9202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 957ms/step - accuracy: 0.0745 - loss: 3.6107 - val_accuracy: 0.1790 - val_loss: 2.6746\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 797ms/step - accuracy: 0.2296 - loss: 2.5637 - val_accuracy: 0.2990 - val_loss: 2.2971\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 774ms/step - accuracy: 0.4178 - loss: 1.9636 - val_accuracy: 0.3257 - val_loss: 2.1594\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 777ms/step - accuracy: 0.6236 - loss: 1.2730 - val_accuracy: 0.3019 - val_loss: 2.7081\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 788ms/step - accuracy: 0.7711 - loss: 0.7910 - val_accuracy: 0.3467 - val_loss: 2.5817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f3e10490d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, steps_per_epoch=250, batch_size=32, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 372ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.2651102e-10, 8.8237440e-03, 1.0483840e-15, ..., 1.3017108e-03,\n",
       "        1.6214914e-07, 6.3771588e-01],\n",
       "       [3.6846899e-04, 4.5482289e-02, 6.2448669e-02, ..., 3.6155707e-03,\n",
       "        2.6788991e-03, 3.0292847e-04],\n",
       "       [7.2188623e-04, 9.1799575e-06, 6.7550660e-05, ..., 9.7286184e-06,\n",
       "        2.8064630e-06, 6.6404618e-06],\n",
       "       ...,\n",
       "       [6.1321293e-04, 4.1997889e-03, 3.9721904e-06, ..., 2.8608914e-03,\n",
       "        1.8111410e-03, 1.6452713e-02],\n",
       "       [3.3187727e-15, 7.1552146e-04, 2.8276863e-13, ..., 5.7776101e-02,\n",
       "        8.8836165e-04, 2.2100368e-01],\n",
       "       [6.3134104e-01, 4.2348489e-05, 7.4917452e-06, ..., 3.1513207e-02,\n",
       "        6.7833878e-02, 1.1677042e-03]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
